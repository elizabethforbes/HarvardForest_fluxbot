# if (abs(start_point - timestamp_col[start_index]) > 1800 || abs(end_point - timestamp_col[end_index]) > 1800) {
# cat("Skipping interval due to no close timepoints:", j, "\n")
# next  # Skip to the next iteration
# }
# Ensure interval_data is not NULL and has valid CO2 data
if (is.null(interval_data) || nrow(interval_data) == 0 || all(is.na(interval_data$co2))) {
next  # Skip this interval entirely
}
# check and see if any should be discarded due to very small delta
# if (abs(interval_data$co2[1] - interval_data[length(interval_data$co2)]) < diff_threshold) {
# cat("Skipping interval due to extremely small delta:", i, "\n")
# next  # Skip to the next iteration
# }
# check and see if any should be discarded because of negative deltas:
# if (interval_data[length(interval_data$co2)] - interval_data$co2[1] < 0){
# cat("Skipping interval due to negative delta:", i, "\n")
# next
# }
# # skip any with truncated interval data:
# if(length(interval_data) < length_threshold) {
#   cat("Skipping interval due to insufficient length:", i, "\n")
#   next # Skip to the next iteration
# }
# # cat("Interval", i, ": Checking data between", start_point, "and", end_point, "\n")
# if (nrow(interval_data) == 0) {
#   cat("  -> No data in this interval\n")
# }
# else {
#   cat("  -> Data count:", nrow(interval_data), "\n")
#   cat("  -> CO2 values range:", range(interval_data$co2, na.rm = TRUE), "\n")
# }
# Remove rows with specific value for co2 indicating a data transmission error, within the interval data
interval_data <- interval_data[interval_data != 65535]
interval_data <- interval_data[interval_data != 65533]
# calculate rho_a, air density in kg/m3, including humidity:
# first step, calculate saturation vapor pressure in hPa
e_star <- 10*(0.61978 * exp((17.27 * time_series_df$tempC)[start_index:end_index]/
(time_series_df$tempC[start_index:end_index] +
273.3))) # saturation vapor pressure, hPa
# next: saturation density (kg water / kg air) given saturation vapor pressure (e_star) and observed air pressure
# 0.62198 = ratio of molecular masses of water and dry air (18.01528 / 28.9645)
x_s <- 0.62198 * e_star / (time_series_df$pressure[start_index:end_index] - e_star)
# next: calculate humidity ratio using saturation density and observed relative humidity:
x <- x_s * time_series_df$humidity[start_index:end_index] / 100 # divide by 100 to convert to a fraction
# finally, calculate the observed density of humidity-corrected air in the chamber:
# first: density of air in kg/m3 using specific gas constant for dry air
rho_d <- (time_series_df$pressure[start_index:end_index] * 100) /
(R_specific * (time_series_df$tempC[start_index:end_index] + 273.15)) # here converting T to Kelvin from Celcius
# air density in kg/m3 with humidity correction as calculated in "x" above:
# 1.609 = gas constant ratio between water vapor and air
rho_a <- rho_d * (1+x) / (1 + 1.609 * x)
# convert (general) co2 in ppm to mol/m3
mol_kg = 1/(mol_mass/1000) # mass of air in mol/kg
# calculate mol of moist air per m3 in the chamber given previously-calculated moist air densities
mol_m3 = mol_kg * rho_a # mass of moist air in chamber in mol/m3
# convert (our observed) co2 in ppm to molar density using chamber volume:
mol_gas_m3 <- mol_m3 * (interval_data/1000000) # returns mol/m3 (conversion from cm3 to m3 = 1,000,000)
# convert molar concentration of CO2 into concentration in kg/m3
kg_gas_m3 <- mol_gas_m3 * (g_per_mol/1000) # (conversion of g to kg = 1000)
# convert to just mass in kg (volume reported in cm3, converting to m3 here, inverse conversion = 0.000001):
kg_gas <- kg_gas_m3 * (volume * 0.000001) # returns kg of co2 in the chamber at each time point in interval
# Linear regression
linear_model <- lm(kg_gas ~ as.numeric(difftime(interval_timestamp, min(interval_timestamp), units = "secs")))
linear_results <- summary(linear_model)
linear_beta <- coef(linear_results)[2]  # Extract the beta coefficient; kg/s
delta_kg_L = linear_beta*(length_interval) # units in kg
delta_g_L = delta_kg_L*1000 # units in g
delta_mol_L = delta_g_L / g_per_mol # units in mols
fluxL = delta_kg_L / length_interval / (area*0.0001) # flux estimate in kg/m2/sec
fluxL_umol = (delta_mol_L*1000000) / length_interval / (area * 0.0001) # flux estimate in umol/m2/sec
# Quadratic regression
quadratic_model <- lm(kg_gas ~
as.numeric(difftime(interval_timestamp, min(interval_timestamp),
units = "secs")) +
I(as.numeric(difftime(interval_timestamp,
min(interval_timestamp),
units = "secs"))^2))
quadratic_results <- summary(quadratic_model)
quadratic_beta <- coef(quadratic_results)[2]  # Extract the beta coefficient; kg/s
delta_kg_Q  = quadratic_beta*(length_interval) # units in kg
delta_g_Q = delta_kg_Q*1000 # units in g
delta_mol_Q = delta_g_Q / g_per_mol # units in mols
fluxQ = delta_kg_Q / length_interval / (area*0.0001) # flux estimate in kg/m2/sec
fluxQ_umol = (delta_mol_Q*1000000) / length_interval / (area * 0.0001) # flux estimate in umol/m2/sec
# Append the results to the dataframe
results_df <- rbind(results_df, data.frame(
start_timestamp = start_point,
end_timestamp = end_point,
hour_of_obs = round(end_point, "hour"),
method = method,
linear_beta = linear_beta, # kg/s
quadratic_beta = quadratic_beta, # kg/s
length_interval = length_interval, # total interval length in seconds
delta_kg_L = linear_beta/length_interval, # units in kg
delta_kg_Q  = quadratic_beta/length_interval, # units in kg
fluxL_kgm2sec = fluxL, # flux estimate in kg/m2/sec
fluxQ_kgm2sec = fluxQ, # flux estimate in kg/m2/sec
fluxL_umolm2sec = fluxL_umol, # flux estimate in umol/m2/sec
fluxQ_umolm2sec = fluxQ_umol  # flux estimate in umol/m2/sec
))
}
# Return the results
return(results_df)
}
fluxes_HF3_TEST <- estimate_flux(time_series_df = rawdat_met_HF3,
start_end_df = startend_HF3_9,
method = "fluxbot",
volume = 10453.806, # cm3
area = 646.328) # cm2
estimate_flux <- function(time_series_df, start_end_df, method, volume, area) {
# Ensure timestamps are in POSIXct format
time_series_df$Time <- as.POSIXct(time_series_df$Time, tz = "America/New_York")
start_end_df$Start <- as.POSIXct(start_end_df$Start, tz = "America/New_York")
start_end_df$End <- as.POSIXct(start_end_df$End, tz = "America/New_York")
results_df <- data.frame()
# Quality control thresholds: if an interval 'fails' any of these it is skipped and excluded from the final output
diff_threshold <- 5 # difference in co2 concentration delta from start-end needs to be greater than 5ppm
max_threshold <- 3000 # eliminate any intervals that contain co2 concentrations greater than 3k ppm
length_threshold <- 15 # the length of an interval needs to be at least 15 observations (40 obs per 4mins interval for fluxbot)
# constants for conversion of concentration to mass:
R_m = 8.314472  # Ideal gas constant for mass [(m3*Pa)/(K*mol)]
R_specific <- 287.058 # specific gas constant for dry air (J/kg*K)
mol_mass <- 28.9628 # molar mass dry air, g/mol
volume <- volume # cm3; volume of fluxbot chamber, typically 768cm3 without additional tubing/attachments
area <- area # cm2; area of soil that fluxbot collar encompasses, typically 81cm2
g_per_mol = 44.009 # molar mass of CO2, g/mol
# Extract timestamp and data columns from the time series dataframe
# timestamp_col <- as.POSIXct(time_series_df$Time, format = "%Y-%m-%d %H:%M:%S", tz = "America/New_York")
for (i in seq_len(nrow(start_end_df))) {
start_point <- start_end_df$Start[i]
end_point <- start_end_df$End[i]
# Find the closest timestamp to start_point and end_point in the time series data itself:
# start_index <- which.min(abs(timestamp_col - start_point))
# end_index <- which.min(abs(timestamp_col - end_point))
# Filter the raw data to the interval
interval_data <- time_series_df %>%
filter(Time >= start_point & Time <= end_point)
# Check if the closest start and end points are within 30 minutes
# if (abs(start_point - timestamp_col[start_index]) > 1800 || abs(end_point - timestamp_col[end_index]) > 1800) {
# cat("Skipping interval due to no close timepoints:", j, "\n")
# next  # Skip to the next iteration
# }
# Ensure interval_data is not NULL and has valid CO2 data
if (is.null(interval_data) || nrow(interval_data) == 0 || all(is.na(interval_data$co2))) {
next  # Skip this interval entirely
}
# check and see if any should be discarded due to very small delta
# if (abs(interval_data$co2[1] - interval_data[length(interval_data$co2)]) < diff_threshold) {
# cat("Skipping interval due to extremely small delta:", i, "\n")
# next  # Skip to the next iteration
# }
# check and see if any should be discarded because of negative deltas:
# if (interval_data[length(interval_data$co2)] - interval_data$co2[1] < 0){
# cat("Skipping interval due to negative delta:", i, "\n")
# next
# }
# # skip any with truncated interval data:
# if(length(interval_data) < length_threshold) {
#   cat("Skipping interval due to insufficient length:", i, "\n")
#   next # Skip to the next iteration
# }
# # cat("Interval", i, ": Checking data between", start_point, "and", end_point, "\n")
# if (nrow(interval_data) == 0) {
#   cat("  -> No data in this interval\n")
# }
# else {
#   cat("  -> Data count:", nrow(interval_data), "\n")
#   cat("  -> CO2 values range:", range(interval_data$co2, na.rm = TRUE), "\n")
# }
# Remove rows with specific value for co2 indicating a data transmission error, within the interval data
interval_data <- interval_data$co2[interval_data$co2 != 65535]
interval_data <- interval_data$co2[interval_data$co2 != 65533]
# calculate rho_a, air density in kg/m3, including humidity:
# first step, calculate saturation vapor pressure in hPa
e_star <- 10*(0.61978 * exp((17.27 * time_series_df$tempC)[start_index:end_index]/
(time_series_df$tempC[start_index:end_index] +
273.3))) # saturation vapor pressure, hPa
# next: saturation density (kg water / kg air) given saturation vapor pressure (e_star) and observed air pressure
# 0.62198 = ratio of molecular masses of water and dry air (18.01528 / 28.9645)
x_s <- 0.62198 * e_star / (time_series_df$pressure[start_index:end_index] - e_star)
# next: calculate humidity ratio using saturation density and observed relative humidity:
x <- x_s * time_series_df$humidity[start_index:end_index] / 100 # divide by 100 to convert to a fraction
# finally, calculate the observed density of humidity-corrected air in the chamber:
# first: density of air in kg/m3 using specific gas constant for dry air
rho_d <- (time_series_df$pressure[start_index:end_index] * 100) /
(R_specific * (time_series_df$tempC[start_index:end_index] + 273.15)) # here converting T to Kelvin from Celcius
# air density in kg/m3 with humidity correction as calculated in "x" above:
# 1.609 = gas constant ratio between water vapor and air
rho_a <- rho_d * (1+x) / (1 + 1.609 * x)
# convert (general) co2 in ppm to mol/m3
mol_kg = 1/(mol_mass/1000) # mass of air in mol/kg
# calculate mol of moist air per m3 in the chamber given previously-calculated moist air densities
mol_m3 = mol_kg * rho_a # mass of moist air in chamber in mol/m3
# convert (our observed) co2 in ppm to molar density using chamber volume:
mol_gas_m3 <- mol_m3 * (interval_data/1000000) # returns mol/m3 (conversion from cm3 to m3 = 1,000,000)
# convert molar concentration of CO2 into concentration in kg/m3
kg_gas_m3 <- mol_gas_m3 * (g_per_mol/1000) # (conversion of g to kg = 1000)
# convert to just mass in kg (volume reported in cm3, converting to m3 here, inverse conversion = 0.000001):
kg_gas <- kg_gas_m3 * (volume * 0.000001) # returns kg of co2 in the chamber at each time point in interval
# Linear regression
linear_model <- lm(kg_gas ~ as.numeric(difftime(interval_timestamp, min(interval_timestamp), units = "secs")))
linear_results <- summary(linear_model)
linear_beta <- coef(linear_results)[2]  # Extract the beta coefficient; kg/s
delta_kg_L = linear_beta*(length_interval) # units in kg
delta_g_L = delta_kg_L*1000 # units in g
delta_mol_L = delta_g_L / g_per_mol # units in mols
fluxL = delta_kg_L / length_interval / (area*0.0001) # flux estimate in kg/m2/sec
fluxL_umol = (delta_mol_L*1000000) / length_interval / (area * 0.0001) # flux estimate in umol/m2/sec
# Quadratic regression
quadratic_model <- lm(kg_gas ~
as.numeric(difftime(interval_timestamp, min(interval_timestamp),
units = "secs")) +
I(as.numeric(difftime(interval_timestamp,
min(interval_timestamp),
units = "secs"))^2))
quadratic_results <- summary(quadratic_model)
quadratic_beta <- coef(quadratic_results)[2]  # Extract the beta coefficient; kg/s
delta_kg_Q  = quadratic_beta*(length_interval) # units in kg
delta_g_Q = delta_kg_Q*1000 # units in g
delta_mol_Q = delta_g_Q / g_per_mol # units in mols
fluxQ = delta_kg_Q / length_interval / (area*0.0001) # flux estimate in kg/m2/sec
fluxQ_umol = (delta_mol_Q*1000000) / length_interval / (area * 0.0001) # flux estimate in umol/m2/sec
# Append the results to the dataframe
results_df <- rbind(results_df, data.frame(
start_timestamp = start_point,
end_timestamp = end_point,
hour_of_obs = round(end_point, "hour"),
method = method,
linear_beta = linear_beta, # kg/s
quadratic_beta = quadratic_beta, # kg/s
length_interval = length_interval, # total interval length in seconds
delta_kg_L = linear_beta/length_interval, # units in kg
delta_kg_Q  = quadratic_beta/length_interval, # units in kg
fluxL_kgm2sec = fluxL, # flux estimate in kg/m2/sec
fluxQ_kgm2sec = fluxQ, # flux estimate in kg/m2/sec
fluxL_umolm2sec = fluxL_umol, # flux estimate in umol/m2/sec
fluxQ_umolm2sec = fluxQ_umol  # flux estimate in umol/m2/sec
))
}
# Return the results
return(results_df)
}
fluxes_HF3_TEST <- estimate_flux(time_series_df = rawdat_met_HF3,
start_end_df = startend_HF3_9,
method = "fluxbot",
volume = 10453.806, # cm3
area = 646.328) # cm2
estimate_flux <- function(time_series_df, start_end_df, method, volume, area) {
# Ensure timestamps are in POSIXct format
time_series_df$Time <- as.POSIXct(time_series_df$Time, tz = "America/New_York")
start_end_df$Start <- as.POSIXct(start_end_df$Start, tz = "America/New_York")
start_end_df$End <- as.POSIXct(start_end_df$End, tz = "America/New_York")
results_df <- data.frame()
# Quality control thresholds: if an interval 'fails' any of these it is skipped and excluded from the final output
diff_threshold <- 5 # difference in co2 concentration delta from start-end needs to be greater than 5ppm
max_threshold <- 3000 # eliminate any intervals that contain co2 concentrations greater than 3k ppm
length_threshold <- 15 # the length of an interval needs to be at least 15 observations (40 obs per 4mins interval for fluxbot)
# constants for conversion of concentration to mass:
R_m = 8.314472  # Ideal gas constant for mass [(m3*Pa)/(K*mol)]
R_specific <- 287.058 # specific gas constant for dry air (J/kg*K)
mol_mass <- 28.9628 # molar mass dry air, g/mol
volume <- volume # cm3; volume of fluxbot chamber, typically 768cm3 without additional tubing/attachments
area <- area # cm2; area of soil that fluxbot collar encompasses, typically 81cm2
g_per_mol = 44.009 # molar mass of CO2, g/mol
# Extract timestamp and data columns from the time series dataframe
# timestamp_col <- as.POSIXct(time_series_df$Time, format = "%Y-%m-%d %H:%M:%S", tz = "America/New_York")
for (i in seq_len(nrow(start_end_df))) {
start_point <- start_end_df$Start[i]
end_point <- start_end_df$End[i]
# Find the closest timestamp to start_point and end_point in the time series data itself:
# start_index <- which.min(abs(timestamp_col - start_point))
# end_index <- which.min(abs(timestamp_col - end_point))
# Filter the raw data to the interval
interval_data <- time_series_df %>%
filter(Time >= start_point & Time <= end_point)
# Check if the closest start and end points are within 30 minutes
# if (abs(start_point - timestamp_col[start_index]) > 1800 || abs(end_point - timestamp_col[end_index]) > 1800) {
# cat("Skipping interval due to no close timepoints:", j, "\n")
# next  # Skip to the next iteration
# }
# Ensure interval_data is not NULL and has valid CO2 data
if (is.null(interval_data) || nrow(interval_data) == 0 || all(is.na(interval_data$co2))) {
next  # Skip this interval entirely
}
# check and see if any should be discarded due to very small delta
# if (abs(interval_data$co2[1] - interval_data[length(interval_data$co2)]) < diff_threshold) {
# cat("Skipping interval due to extremely small delta:", i, "\n")
# next  # Skip to the next iteration
# }
# check and see if any should be discarded because of negative deltas:
# if (interval_data[length(interval_data$co2)] - interval_data$co2[1] < 0){
# cat("Skipping interval due to negative delta:", i, "\n")
# next
# }
# # skip any with truncated interval data:
# if(length(interval_data) < length_threshold) {
#   cat("Skipping interval due to insufficient length:", i, "\n")
#   next # Skip to the next iteration
# }
# # cat("Interval", i, ": Checking data between", start_point, "and", end_point, "\n")
# if (nrow(interval_data) == 0) {
#   cat("  -> No data in this interval\n")
# }
# else {
#   cat("  -> Data count:", nrow(interval_data), "\n")
#   cat("  -> CO2 values range:", range(interval_data$co2, na.rm = TRUE), "\n")
# }
# # Remove rows with specific value for co2 indicating a data transmission error, within the interval data
# interval_data <- interval_data[interval_data != 65535]
# interval_data <- interval_data[interval_data != 65533]
# calculate rho_a, air density in kg/m3, including humidity:
# first step, calculate saturation vapor pressure in hPa
e_star <- 10*(0.61978 * exp((17.27 * time_series_df$tempC)[start_index:end_index]/
(time_series_df$tempC[start_index:end_index] +
273.3))) # saturation vapor pressure, hPa
# next: saturation density (kg water / kg air) given saturation vapor pressure (e_star) and observed air pressure
# 0.62198 = ratio of molecular masses of water and dry air (18.01528 / 28.9645)
x_s <- 0.62198 * e_star / (time_series_df$pressure[start_index:end_index] - e_star)
# next: calculate humidity ratio using saturation density and observed relative humidity:
x <- x_s * time_series_df$humidity[start_index:end_index] / 100 # divide by 100 to convert to a fraction
# finally, calculate the observed density of humidity-corrected air in the chamber:
# first: density of air in kg/m3 using specific gas constant for dry air
rho_d <- (time_series_df$pressure[start_index:end_index] * 100) /
(R_specific * (time_series_df$tempC[start_index:end_index] + 273.15)) # here converting T to Kelvin from Celcius
# air density in kg/m3 with humidity correction as calculated in "x" above:
# 1.609 = gas constant ratio between water vapor and air
rho_a <- rho_d * (1+x) / (1 + 1.609 * x)
# convert (general) co2 in ppm to mol/m3
mol_kg = 1/(mol_mass/1000) # mass of air in mol/kg
# calculate mol of moist air per m3 in the chamber given previously-calculated moist air densities
mol_m3 = mol_kg * rho_a # mass of moist air in chamber in mol/m3
# convert (our observed) co2 in ppm to molar density using chamber volume:
mol_gas_m3 <- mol_m3 * (interval_data/1000000) # returns mol/m3 (conversion from cm3 to m3 = 1,000,000)
# convert molar concentration of CO2 into concentration in kg/m3
kg_gas_m3 <- mol_gas_m3 * (g_per_mol/1000) # (conversion of g to kg = 1000)
# convert to just mass in kg (volume reported in cm3, converting to m3 here, inverse conversion = 0.000001):
kg_gas <- kg_gas_m3 * (volume * 0.000001) # returns kg of co2 in the chamber at each time point in interval
# Linear regression
linear_model <- lm(kg_gas ~ as.numeric(difftime(interval_timestamp, min(interval_timestamp), units = "secs")))
linear_results <- summary(linear_model)
linear_beta <- coef(linear_results)[2]  # Extract the beta coefficient; kg/s
delta_kg_L = linear_beta*(length_interval) # units in kg
delta_g_L = delta_kg_L*1000 # units in g
delta_mol_L = delta_g_L / g_per_mol # units in mols
fluxL = delta_kg_L / length_interval / (area*0.0001) # flux estimate in kg/m2/sec
fluxL_umol = (delta_mol_L*1000000) / length_interval / (area * 0.0001) # flux estimate in umol/m2/sec
# Quadratic regression
quadratic_model <- lm(kg_gas ~
as.numeric(difftime(interval_timestamp, min(interval_timestamp),
units = "secs")) +
I(as.numeric(difftime(interval_timestamp,
min(interval_timestamp),
units = "secs"))^2))
quadratic_results <- summary(quadratic_model)
quadratic_beta <- coef(quadratic_results)[2]  # Extract the beta coefficient; kg/s
delta_kg_Q  = quadratic_beta*(length_interval) # units in kg
delta_g_Q = delta_kg_Q*1000 # units in g
delta_mol_Q = delta_g_Q / g_per_mol # units in mols
fluxQ = delta_kg_Q / length_interval / (area*0.0001) # flux estimate in kg/m2/sec
fluxQ_umol = (delta_mol_Q*1000000) / length_interval / (area * 0.0001) # flux estimate in umol/m2/sec
# Append the results to the dataframe
results_df <- rbind(results_df, data.frame(
start_timestamp = start_point,
end_timestamp = end_point,
hour_of_obs = round(end_point, "hour"),
method = method,
linear_beta = linear_beta, # kg/s
quadratic_beta = quadratic_beta, # kg/s
length_interval = length_interval, # total interval length in seconds
delta_kg_L = linear_beta/length_interval, # units in kg
delta_kg_Q  = quadratic_beta/length_interval, # units in kg
fluxL_kgm2sec = fluxL, # flux estimate in kg/m2/sec
fluxQ_kgm2sec = fluxQ, # flux estimate in kg/m2/sec
fluxL_umolm2sec = fluxL_umol, # flux estimate in umol/m2/sec
fluxQ_umolm2sec = fluxQ_umol  # flux estimate in umol/m2/sec
))
}
# Return the results
return(results_df)
}
fluxes_HF3_TEST <- estimate_flux(time_series_df = rawdat_met_HF3,
start_end_df = startend_HF3_9,
method = "fluxbot",
volume = 10453.806, # cm3
area = 646.328) # cm2
fluxes_HF3_TEST <- estimate_flux(time_series_df = rawdat_met_HF3,
start_end_df = startend_HF3_9,
method = "fluxbot",
volume = 10453.806, # cm3
area = 646.328) # cm2
# libraries:
library(tidyverse)
library(readxl)
library(readr)
# data:
pilevol <- read_csv("/Users/elizabethforbes/Documents/Hudson Carbon/Kristen Tam - Mesc thesis research/windrow_volume_2023.xlsx")
View(pilevol)
# data:
pilevol <- read_xlsx("/Users/elizabethforbes/Documents/Hudson Carbon/Kristen Tam - Mesc thesis research/windrow_volume_2023.xlsx")
View(pilevol)
# split into control, experimental (we're interested in control)
pilevol_cont <- pilevol %>%
filter(treatment == "C") %>%
# select for after turning, since the bulk density is lessened by this manipulation
filter(before_after_turning == "after")
View(pilevol_cont)
# calculate percent volume lost over whole interval:
(pilevol_cont$Volume[1] - pilevol_cont$Volume[9])/pilevol_cont$Volume[1]
# July
((pilevol_cont$Volume[1] - pilevol_cont$Volume[4])/pilevol_cont$Volume[1]) +
# August
((pilevol_cont$Volume[4] - pilevol_cont$Volume[6])/pilevol_cont$Volume[4]) +
# September
((pilevol_cont$Volume[6] - pilevol_cont$Volume[8])/pilevol_cont$Volume[6])
# July
((pilevol_cont$Volume[1] - pilevol_cont$Volume[4])/pilevol_cont$Volume[1])
# August
((pilevol_cont$Volume[4] - pilevol_cont$Volume[6])/pilevol_cont$Volume[4])
# September
((pilevol_cont$Volume[6] - pilevol_cont$Volume[8])/pilevol_cont$Volume[6])
# July:
(pilevol_cont$Volume[1] - pilevol_cont$Volume[4])/pilevol_cont$Volume[1]
# August:
(pilevol_cont$Volume[4] - pilevol_cont$Volume[6])/pilevol_cont$Volume[4]
# September
(pilevol_cont$Volume[6] - pilevol_cont$Volume[8])/pilevol_cont$Volume[6]
# half of October
(pilevol_cont$Volume[8] - pilevol_cont$Volume[9])/pilevol_cont$Volume[8]
# July:  36% -- weekly:
((pilevol_cont$Volume[1] - pilevol_cont$Volume[4])/pilevol_cont$Volume[1])/4
# August: 5% -- weekly:
((pilevol_cont$Volume[4] - pilevol_cont$Volume[6])/pilevol_cont$Volume[4])/4
# September: 18%
((pilevol_cont$Volume[6] - pilevol_cont$Volume[8])/pilevol_cont$Volume[6])/4
# half of October:
(pilevol_cont$Volume[8] - pilevol_cont$Volume[9])/pilevol_cont$Volume[8]
# half of October: -13% -- weekly:
((pilevol_cont$Volume[8] - pilevol_cont$Volume[9])/pilevol_cont$Volume[8])/2
# split into control, experimental (we're interested in control)
pilevol_cont <- pilevol %>%
filter(treatment == "C") %>%
# select for after turning, since the bulk density is lessened by this manipulation
filter(before_after_turning == "before")
# calculate percent volume lost over whole interval:
(pilevol_cont$Volume[1] - pilevol_cont$Volume[9])/pilevol_cont$Volume[1]
# July:  36% -- weekly: 9%
((pilevol_cont$Volume[1] - pilevol_cont$Volume[4])/pilevol_cont$Volume[1])/4
# August: 5% -- weekly: 1.3%
((pilevol_cont$Volume[4] - pilevol_cont$Volume[6])/pilevol_cont$Volume[4])/4
# September: 18% -- weekly: 5%
((pilevol_cont$Volume[6] - pilevol_cont$Volume[8])/pilevol_cont$Volume[6])/4
# half of October: -13% -- weekly: -6%
((pilevol_cont$Volume[8] - pilevol_cont$Volume[9])/pilevol_cont$Volume[8])/2
# July:  36% -- weekly: 9%
((pilevol_cont$Volume[1] - pilevol_cont$Volume[4])/pilevol_cont$Volume[1])/4
# split into control, experimental (we're interested in control)
pilevol_cont <- pilevol %>%
filter(treatment == "C") %>%
# select for after turning, since the bulk density is lessened by this manipulation
filter(before_after_turning == "after")
?read_xlsx
# data:
pilevol <- read_xlsx("/Users/elizabethforbes/Documents/Hudson Carbon/Kristen Tam - Mesc thesis research/windrow_volume_2023.xlsx",
sheet = 1)
View(pilevol)
# BULK DENSITY:
pileBD_cont <- read_xlsx("/Users/elizabethforbes/Documents/Hudson Carbon/Kristen Tam - Mesc thesis research/windrow_volume_2023.xlsx",
sheet = 2)
# BULK DENSITY:
pileBD_cont <- read_xlsx("/Users/elizabethforbes/Documents/Hudson Carbon/Kristen Tam - Mesc thesis research/windrow_volume_2023.xlsx",
sheet = 2)
View(pileBD_cont)
pileBD_cont <- pileBD_cont %>% select(DOY, C)
# change in BD over time:
pileBD_cont$C[12] - pileBD_cont$C[1]
# 11 total
# change in BD per day:
11/(pileBD_cont$DOY[12] - pileBD_cont$DOY[1])
# percent change in BD per day, per month:
(pileBD_cont$C[1] - pileBD_cont$C[12])/pileBD_cont$C[1]
# percent change in BD per day, per month:
abs((pileBD_cont$C[1] - pileBD_cont$C[12])/pileBD_cont$C[1])
# percent change in BD per day, per month:
abs((pileBD_cont$C[12] - pileBD_cont$C[1])/pileBD_cont$C[12])
# 0.6376812, or an increase in 64% bulk density over the months recorded...divide by number of days
0.6376812 / (pileBD_cont$DOY[12] - pileBD_cont$DOY[1])
0.004830918*100
# 0.6376812, or an increase in 64% bulk density over the months recorded...divide by number of days
0.6376812 / (pileBD_cont$DOY[12] - pileBD_cont$DOY[1]) * 7
# on AVERAGE over the whole time, what's the volume loss per week?
((pilevol_cont$Volume[1] - pilevol_cont$Volume[9])/pilevol_cont$Volume[1])/
(pilevol_cont$date[9] - pilevol_cont$date[1])
# on AVERAGE over the whole time, what's the volume loss per week?
((pilevol_cont$Volume[1] - pilevol_cont$Volume[9])/pilevol_cont$Volume[1])/
as.numeric(pilevol_cont$date[9] - pilevol_cont$date[1])
# on AVERAGE over the whole time, what's the volume loss per week?
((pilevol_cont$Volume[1] - pilevol_cont$Volume[9])/pilevol_cont$Volume[1])/
as.numeric(pilevol_cont$date[9] - pilevol_cont$date[1]) * 7
# how much volume does 100lbs of 1month compost occupy?
# between june 7th and july 19th 2023, bulk density went from 6.25 to 12.5.  right now assuming lbs/yd3, but we'd have to multiply that by forty
12.5 * 40
# what would this have weighed at the start?
# 1/5th cubic yard = ~ .15m3
# assume that 0.15m3 after one month was 12% less volume than at the start
.15 * 1.12
# what would this have weighed at the start?
# 1/5th cubic yard = ~ .15m3
# assume that 0.15m3 after one month was 12% less volume than at the start
0.152911 * 1.12
3.4*4
# assuming a rough 2:1 ratio of manure to hay, this would mean that the fresh input for 100lbs of compost:
129/2
