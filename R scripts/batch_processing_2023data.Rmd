---
title: "processing 2023 data"
output: html_document
date: "2024-02-22"
---

```{r setup, include=FALSE}
library(tidyverse)
library(readxl)
library(here)
library(purrr)
```

## Import XLSX files as list of dfs

```{r}
# function to import a single xlsx file with each tab as a separate df in a list of dfs with the name of the tab as the df name
read_excel_allsheets <- function(filename, tibble = FALSE) {
    # I prefer straight data.frames
    # but if you like tidyverse tibbles (the default with read_excel)
    # then just pass tibble = TRUE
    sheets <- readxl::excel_sheets(filename)
    x <- lapply(sheets, function(X) readxl::read_excel(filename, sheet = X))
    if(!tibble) x <- lapply(x, as.data.frame)
    names(x) <- sheets
    x
}

# source:
# https://stackoverflow.com/questions/12945687/read-all-worksheets-in-an-excel-workbook-into-an-r-list-with-data-frames
```

Import fluxbot data sheets:
```{r}
co2 <- read_excel_allsheets(here("fluxbot data 2023", "fluxbot_co2.xlsx"), 
                            tibble = FALSE)
rh <- read_excel_allsheets(here("fluxbot data 2023", "fluxbot_humidity.xlsx"),
                           tibble = FALSE)
temp <- read_excel_allsheets(here("fluxbot data 2023", "fluxbot_temperature.xlsx"),
                             tibble = FALSE)
press <- read_excel_allsheets(here("fluxbot data 2023", "fluxbot_pressure.xlsx"),
                              tibble = FALSE)
```

## Process with custom R function ("process_data"): takes Google style data and transposes it into long-form data, and transforms the UNIX timestamp to POSIXct, and writes those files as CSV files to the source folder, as well as storing it as a list itself

```{r}

# file named "process_googledata_list.R" in folder "scripts_batch processing fluxbot data" in this directory
source(here("scripts_batch processing fluxbot data", "process_googledata_list.R"))

co2_rawdata <- process_data(co2, col1 = "device timestamps", col2 = "co2")
rh_rawdata <- process_data(rh, col1 = "device timestamps", col2 = "humidity")
temp_rawdata <- process_data(temp, col1 = "device timestamps", col2 = "temprerature") # edit to note: there's a typo in the fluxbot software that produces a column named temprerature in the output on Google forms; need to fix
press_rawdata <- process_data(press, col1 = "device timestamps", col2 = "pressure")
```

## Merge all four dataframes (co2, RH, T, and P) by their common factor (timestamps)
```{r}

# file named "merge_metadata_list.R" in folder "scripts_batch processing fluxbot data" in this directory
source(here("scripts_batch processing fluxbot data", "merge_metadata_list.R"))

merged_result <- merge_lists_by_column(co2_rawdata, rh_rawdata, temp_rawdata, press_rawdata, "UNIX")

# Function to change column names and convert specified columns to numeric
change_colnames_and_convert <- function(lst) {
  lapply(lst, function(df) {
    # Change column names
    colnames(df) <- c("Time", "co2", "humidity", "tempC", "pressure")
    
    # Convert specific columns to numeric (assuming they are character)
    df$Time <- as.numeric(df$Time)
    df$Time <- as.POSIXct(df$Time, format = "%Y-%m-%d %H:%M:%S", tz = "America/New_York")
    df$co2 <- as.numeric(df$co2)
    df$humidity <- as.numeric(df$humidity)
    df$tempC <- as.numeric(df$tempC)
    df$pressure <- as.numeric(df$pressure)
    
    return(df)
  })
}

# Apply the function to the list of lists: result will be a list of dataframes with all indicated columns of class "numeric", and updated colnames
allfluxbotdata_list <- change_colnames_and_convert(merged_result)

```

## Extract start/end df for the period of deployment in question: October-November 2023

```{r}
# extract all datetimes, then find min and max of all:
all_datetimes <- unlist(lapply(allfluxbotdata_list, function(df) df$Time))

# find earliest (min) and latest (max) datetime after deployment in HF:
# first define start date of deployment:
startdate <- as.POSIXct("2023-10-01 00:00:00 EDT")

# filter data for that after startdate defined above:
all_datetimesfiltered <- all_datetimes[all_datetimes > startdate]
as.POSIXct(min(all_datetimesfiltered))
# [1] "2023-10-01 00:00:02 EDT"
as.POSIXct(max(all_datetimesfiltered))
# [1] "2023-11-04 01:00:09 EDT"

# generate a viable start-end df: this will have start/end brackets for the wanted observation intervals for every hour between the earliest and latest datetimes identified above (this can also be determined manually)
start_datetime <- as.POSIXct("2023-10-01 00:00:02")
end_datetime <- as.POSIXct("2023-11-04 01:00:09")
interval_length <- as.difftime(1, units = "hours")  # 1 hour interval

# function titled "extract_startend_intervals_df.R" in folder "scripts_batch processing fluxbot data" in this directory
start_end <- generate_interval_df(start_datetime, end_datetime,
                                  interval_length,
                                  start_minute = 56, start_second = 00,
                                  end_minute = 59, end_second = 59)

```


## Meteorological data from HF deployment: tower located near deployment site

```{r}

# Produce pressure data from HF met station:
# load HF met data from 2016 - 2017 and convert to useful units
met_data <- read.csv("https://harvardforest.fas.harvard.edu/data/p00/hf001/hf001-10-15min-m.csv")
met_data$ymd <- ymd(str_split_fixed(met_data$datetime, "T", 2)[,1])
met_data$time <- hm(str_split_fixed(met_data$datetime, "T", 2)[,2])
met_data <- met_data[which(met_data$ymd>=ymd("2023-06-01") & met_data$ymd<ymd("2023-11-30")),]
#unit conversions: not necessary as mbar = hPa (just rename)
met_data <- met_data %>% 
  select(datetime, bar, airt, prec, s10t) %>% 
  rename(pressure_hPa_HF = bar,
         tempC_HF = airt,
         precip_HF = prec,
         soiltemp_10cm_HF = s10t)
met_data <- met_data %>% 
  mutate(Time = as.POSIXct(datetime,
                           format = "%Y-%m-%dT%H:%M",
                           tz = "America/New_York"))

# assign met data values to each df in the HF deployment array with a rolling join (dplyr)
# test <- rawdata_fluxbot_100 %>% 
#   left_join(met_data,
#             join_by(closest(Time>=Time))) %>% 
#   # keep Time.x (from rawdata) and drop Time.y (from met-data)
#   select(Time.x, co2, humidity, tempC, pressure, 
#          pressure_hPa_HF, tempC_HF, precip_HF, soiltemp_10cm_HF) %>% 
#   rename(Time = Time.x,
#          pressure_onboard = pressure,
#          pressure = pressure_hPa_HF) #rename HF pressure to "pressure" for flux esimate process
# 
# test_fluxes <- calculate_regressions_custom_intervals(test, start_end, "fluxbot", 768, 81)
# 
# head(test_fluxes)
```

Assign HF meterological data to each of the dfs in the HF deployment array:
```{r}

# Define a function to apply the process to a single data frame
join_met_data <- function(df) {
  df <- df %>%
    left_join(met_data,
              join_by(closest(Time>=Time))) %>% 
              # by = c("closest" = "Time")) %>%
    select(Time.x, co2, humidity, tempC, pressure, 
           pressure_hPa_HF, tempC_HF, precip_HF, soiltemp_10cm_HF) %>%
    rename(Time = Time.x,
           pressure_onboard = pressure,
           pressure = pressure_hPa_HF)
  
  return(df)
}

# make list:
# rawdata_bots <- list(rawdata_fluxbot_100=rawdata_fluxbot_100,
#                                      rawdata_fluxbot_13=rawdata_fluxbot_13,
#                                      rawdata_fluxbot_22=rawdata_fluxbot_22,
#                                      rawdata_fluxbot_114=rawdata_fluxbot_114,
#                                      rawdata_fluxbot_108=rawdata_fluxbot_108,
#                                      rawdata_fluxbot_101=rawdata_fluxbot_101,
#                                      rawdata_fluxbot_112=rawdata_fluxbot_112,
#                                      rawdata_fluxbot_111=rawdata_fluxbot_111, # "healthy" bots
#                                      rawdata_fluxbot_113=rawdata_fluxbot_113,
#                                      rawdata_fluxbot_103=rawdata_fluxbot_103,
#                                      rawdata_fluxbot_102=rawdata_fluxbot_102,
#                                      rawdata_fluxboy_105=rawdata_fluxboy_105,
#                                      rawdata_fluxbot_24=rawdata_fluxbot_24,
#                                      rawdata_fluxbot_106=rawdata_fluxbot_106,
#                                      rawdata_fluxbot_104=rawdata_fluxbot_104,
#                                      rawdata_fluxbot_110=rawdata_fluxbot_110)

rawdata_bots <- allfluxbotdata_list

# Apply the function to each data frame in the list
fluxbots_metdata_list <- lapply(rawdata_bots,
                                join_met_data)

# Write each data frame in the resulting list to the global environment with its original name
for (i in seq_along(fluxbots_metdata_list)) {
  assign(names(rawdata_bots)[i], fluxbots_metdata_list[[i]])
}
```


Flux estimates:
```{r}
# function titled "estimatefluxes.R" in folder "scripts_batch processing fluxbot data" in this directory:
source(here("scripts_batch processing fluxbot data", "estimatefluxes.R"))

# fluxbots in the healthy plot:
fluxes_bot100 <- calculate_regressions_custom_intervals(rawdata_fluxbot_100, start_end, "fluxbot", 768, 81)
fluxes_bot13 <- calculate_regressions_custom_intervals(rawdata_fluxbot_13, start_end, "fluxbot", 768, 81)
fluxes_bot22 <- calculate_regressions_custom_intervals(rawdata_fluxbot_22, start_end, "fluxbot", 768, 81)
fluxes_bot114 <- calculate_regressions_custom_intervals(rawdata_fluxbot_114, start_end, "fluxbot", 768, 81)
fluxes_bot108 <- calculate_regressions_custom_intervals(rawdata_fluxbot_108, start_end, "fluxbot", 768, 81) 
fluxes_bot101 <- calculate_regressions_custom_intervals(rawdata_fluxbot_101, start_end, "fluxbot", 768, 81)
fluxes_bot112 <- calculate_regressions_custom_intervals(rawdata_fluxbot_112, start_end, "fluxbot", 768, 81)
fluxes_bot111 <- calculate_regressions_custom_intervals(rawdata_fluxbot_111, start_end, "fluxbot", 768, 81)
healthybots <- bind_rows(lst(
  fluxes_bot100, 
  fluxes_bot13, 
  fluxes_bot22, 
  fluxes_bot114, 
  fluxes_bot108, 
  fluxes_bot101, 
  # fluxes_bot112, 
  fluxes_bot111), 
  .id = "id")
healthybots <- healthybots %>% 
  mutate(stand = "healthy")

# fluxbots in the diseased plot:
fluxes_bot113 <- calculate_regressions_custom_intervals(rawdata_fluxbot_113, start_end, "fluxbot", 768, 81)
fluxes_bot103 <- calculate_regressions_custom_intervals(rawdata_fluxbot_103, start_end, "fluxbot", 768, 81)
fluxes_bot102 <- calculate_regressions_custom_intervals(rawdata_fluxbot_102, start_end, "fluxbot", 768, 81)
fluxes_bot105 <- calculate_regressions_custom_intervals(rawdata_fluxboy_105, start_end, "fluxbot", 768, 81) #Error: object 'rawdata_fluxbot_105' not found; yeah there was a typo in the fluxbot name!
fluxes_bot24 <- calculate_regressions_custom_intervals(rawdata_fluxbot_24, start_end, "fluxbot", 768, 81) 
fluxes_bot106 <- calculate_regressions_custom_intervals(rawdata_fluxbot_106, start_end, "fluxbot", 768, 81)
fluxes_bot104 <- calculate_regressions_custom_intervals(rawdata_fluxbot_104, start_end, "fluxbot", 768, 81)
fluxes_bot110 <- calculate_regressions_custom_intervals(rawdata_fluxbot_110, start_end, "fluxbot", 768, 81)
unhealthybots <- bind_rows(lst(fluxes_bot113, fluxes_bot103, fluxes_bot102, fluxes_bot105, fluxes_bot24, fluxes_bot106,
                             fluxes_bot104, fluxes_bot110), .id = "id")
unhealthybots <- unhealthybots %>% 
  mutate(stand = "unhealthy")

HF_fluxestimates <- rbind(healthybots, unhealthybots)
HF_fluxestimates <- HF_fluxestimates %>% 
  filter(hour_of_obs > "2023-10-02 00:00:00" &
           hour_of_obs < "2023-11-17 00:00:00")

# select the flux estimate that was produced with the higher of the two beta values
HF_fluxestimates <- HF_fluxestimates %>% 
  mutate(final_flux_umolm2sec =
           case_when(linear_beta > quadratic_beta ~ fluxL_umolm2sec,
                   quadratic_beta > linear_beta ~ fluxQ_umolm2sec))

write.csv(HF_fluxestimates, "HarvardForest_fluxestimates_fall2023.csv")
```

#####################
Translate HF autochamber array data into flux estimates using pressure data from meteorological tower (as we did for the fluxbots, above).

Download data:
```{r}

```

